{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High tip classification - Random Forest\n",
    "\n",
    "## Spark\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1280px-Apache_Spark_logo.svg.png\" width=\"400\">\n",
    "\n",
    "**Hardware**: 10 nodes - r5.8xlarge (32 CPU, 256GB RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TAXI_S3'] = 's3://saturn-titan/nyc-taxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils import MLUtils\n",
    "\n",
    "ml_utils = MLUtils(\n",
    "    ml_task='high_tip',\n",
    "    tool='spark',\n",
    "    model='random_forest',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 ms, sys: 0 ns, total: 2.82 ms\n",
      "Wall time: 9.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219889897"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tip_train = spark.read.parquet(f'{ml_utils.taxi_path}/data/ml/tip_train')\n",
    "tip_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='e54881cf13434e2482468589053b046c', pickup_datetime=datetime.datetime(2018, 5, 25, 8, 49, 20), dropoff_datetime=datetime.datetime(2018, 5, 25, 9, 12, 59), pickup_taxizone_id=33.0, dropoff_taxizone_id=158.0, pickup_weekday=4, pickup_weekofyear=21, pickup_hour=8, pickup_minute=49, pickup_week_hour=104, passenger_count=1.0, tip_fraction=0.20842105263157895)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can use the full data with Spark so no need to sample here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier\n",
    "\n",
    "We'll train a classifier than can predict \"high-tip\" rides - those where the tip percent is >25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ml_utils.tip_vars.features\n",
    "high_tip = ml_utils.tip_vars.high_tip\n",
    "y_col = ml_utils.tip_vars.y_col\n",
    "\n",
    "tip_train = tip_train.withColumn('label', (tip_train[y_col] > high_tip).cast(T.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|label|    count|\n",
      "+-----+---------+\n",
      "|    1| 58310016|\n",
      "|    0|161579881|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip_train.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol='features',\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform features first to isolate random forest runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.43 ms, sys: 426 Âµs, total: 6.85 ms\n",
      "Wall time: 23.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219889897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "assembler_fitted = pipeline.fit(tip_train)\n",
    "X = assembler_fitted.transform(tip_train)\n",
    "\n",
    "X.cache()\n",
    "X.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(numTrees=100, maxDepth=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 14.7 ms, total: 155 ms\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ml_utils.time_fit():\n",
    "    fitted = rfc.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_test = spark.read.parquet(f'{ml_utils.taxi_path}/data/ml/tip_test')\n",
    "tip_test = tip_test.withColumn('label', (tip_test[y_col] > high_tip).cast(T.IntegerType()))\n",
    "\n",
    "preds = fitted.transform(assembler_fitted.transform(tip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id='2e8f402e4dc44f2fae8b9328a237c4d2', pickup_datetime=datetime.datetime(2019, 9, 9, 10, 19, 44), dropoff_datetime=datetime.datetime(2019, 9, 9, 10, 31, 26), pickup_taxizone_id=162.0, dropoff_taxizone_id=170.0, pickup_weekday=0, pickup_weekofyear=37, pickup_hour=10, pickup_minute=19, pickup_week_hour=10, passenger_count=1.0, tip_fraction=0.11764705882352941, label=0, features=DenseVector([0.0, 37.0, 10.0, 10.0, 19.0, 1.0, 162.0, 170.0]), rawPrediction=DenseVector([78.7087, 21.2913]), probability=DenseVector([0.7871, 0.2129]), prediction=0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+\n",
      "|                  id|             actual| predicted|\n",
      "+--------------------+-------------------+----------+\n",
      "|2e8f402e4dc44f2fa...|0.11764705882352941|0.21291299|\n",
      "|5f067a4121244f42b...| 0.2168421052631579|0.20769915|\n",
      "|60e8442d3d434df49...|               0.15|0.21291299|\n",
      "|2d1537ce2ed347778...|            0.10625| 0.2546924|\n",
      "|13bb8a9ecbd04b559...|                0.0|0.22621535|\n",
      "+--------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# need to convert spark DenseVector to array type to extract positive class probability\n",
    "to_array = F.udf(lambda v: v.toArray().tolist(), T.ArrayType(T.FloatType()))\n",
    "\n",
    "(preds\n",
    " .select(preds.id, preds[y_col].alias('actual'), to_array(preds.probability)[1].alias('predicted'))\n",
    " .show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://saturn-titan/nyc-taxi/ml_results/predictions/high_tip__spark__random_forest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f'{ml_utils.taxi_path}/ml_results/predictions/{ml_utils.ml_task}__{ml_utils.tool}__{ml_utils.model}'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 5.12 ms, total: 17.4 ms\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(preds\n",
    " .select(preds.id, preds[y_col].alias('actual'), to_array(preds.probability)[1].alias('predicted'))\n",
    " .write.parquet(path, mode='overwrite')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_task</th>\n",
       "      <th>tool</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>fit_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_tip</td>\n",
       "      <td>spark</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.536425</td>\n",
       "      <td>1117.825969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ml_task   tool          model metric     value  fit_seconds\n",
       "0  high_tip  spark  random_forest    auc  0.536425  1117.825969"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(preds)\n",
    "ml_utils.write_metric_df('auc', auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
