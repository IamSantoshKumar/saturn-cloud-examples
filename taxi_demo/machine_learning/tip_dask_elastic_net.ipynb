{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "## Dask\n",
    "\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal.svg\" width=\"400\">\n",
    "\n",
    "**Hardware**: 10 nodes - r5.8xlarge's (32 CPU, 256 GB RAM each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils import MLUtils\n",
    "\n",
    "ml_utils = MLUtils(\n",
    "    ml_task='tip',\n",
    "    tool='dask',\n",
    "    model='elastic_net',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-08 16:25:15] INFO - dask-saturn | Cluster is ready\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27fe411db644890a4b47e95dad97d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_saturn import SaturnCluster\n",
    "\n",
    "cluster = SaturnCluster(n_workers=10, scheduler_size='xlarge', worker_size='8xlarge', nthreads=32)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.5 ms, sys: 10.9 ms, total: 92.4 ms\n",
      "Wall time: 2.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10994502"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tip_train = dd.read_parquet(f'{ml_utils.taxi_path}/data/ml/tip_train_sample', engine='pyarrow')\n",
    "len(tip_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's take the same sample we used in the single node scikit example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099448"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tip_train.sample(frac=0.1, replace=False, random_state=42)\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run grid search\n",
    "\n",
    "- use `dask-ml` preprocessing and grid search classes\n",
    "- still using `sklearn.linear_model.ElasticNet` for model fitting\n",
    "- we won't `refit` with best model, because we want to use `dask_ml.wrappers.ParallelPostFit` to use dask to parallelize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from dask_ml.compose import ColumnTransformer\n",
    "from dask_ml.preprocessing import StandardScaler, DummyEncoder, Categorizer\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "features = ml_utils.tip_vars.features\n",
    "y_col = ml_utils.tip_vars.y_col\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('categorize', Categorizer(columns=ml_utils.tip_vars.categorical_feat)),\n",
    "    ('onehot', DummyEncoder(columns=ml_utils.tip_vars.categorical_feat)),\n",
    "    ('scale', ColumnTransformer(transformers=[('num', StandardScaler(), ml_utils.tip_vars.numeric_feat)])),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100)),\n",
    "])\n",
    "\n",
    "params = ml_utils.tip_vars.elastic_net_grid_search_params\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, cv=3, scoring='neg_mean_squared_error', refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('score-07567af67359c1f1e449912522b9d9df', 118, 1) has failed... retrying\n",
      "('score-07567af67359c1f1e449912522b9d9df', 102, 0) has failed... retrying\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 115 ms, total: 1.22 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ml_utils.time_fit():\n",
    "    _ = grid_search.fit(sample[features], sample[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best_params manually because we set `refit=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0, 'clf__l1_ratio': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = (pd.DataFrame(grid_search.cv_results_)\n",
    "               .sort_values('mean_test_score', ascending=False)\n",
    "               .loc[0, 'params'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "This wrapper allows us to parallelize predictions using Dask. The `fit` step is not affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 344 ms, sys: 244 ms, total: 588 ms\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "\n",
    "best_estimator = ParallelPostFit(estimator=pipeline)\n",
    "_ = best_estimator.fit(sample[features], sample[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Grab the sklearn estimator out of the dask wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading model to 's3://saturn-titan/nyc-taxi/ml_results/models/tip__dask__elastic_net.pkl'\n",
      "successfully uploaded model\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator = best_estimator.estimator.named_steps['clf']\n",
    "ml_utils.write_model(sklearn_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set\n",
    "\n",
    "And calculate metrics. Save predictions and metrics to S3.\n",
    "\n",
    "Notice that the below cell runs super fast, because it hasn't actually done anything due to Dask's lazy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 7.55 ms, total: 156 ms\n",
      "Wall time: 620 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tip_test = dd.read_parquet(f'{ml_utils.taxi_path}/data/ml/tip_test', engine='pyarrow')\n",
    "preds = tip_test[['id', y_col]].copy()\n",
    "preds.columns = ['id', 'actual']\n",
    "preds = preds.assign(predicted=best_estimator.predict(tip_test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `persist` the DataFrame to compute all the predictions and store in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.6 ms, sys: 4.61 ms, total: 78.2 ms\n",
      "Wall time: 8.22 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e8f402e4dc44f2fae8b9328a237c4d2</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.218926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f067a4121244f42bf460867c23b39c9</td>\n",
       "      <td>0.216842</td>\n",
       "      <td>0.218926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60e8442d3d434df4959261905a279f55</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.218926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d1537ce2ed347778e078eaee7eacd44</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.218926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13bb8a9ecbd04b559b7b9e40904026b0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id    actual  predicted\n",
       "0  2e8f402e4dc44f2fae8b9328a237c4d2  0.117647   0.218926\n",
       "1  5f067a4121244f42bf460867c23b39c9  0.216842   0.218926\n",
       "2  60e8442d3d434df4959261905a279f55  0.150000   0.218926\n",
       "3  2d1537ce2ed347778e078eaee7eacd44  0.106250   0.218926\n",
       "4  13bb8a9ecbd04b559b7b9e40904026b0  0.000000   0.218926"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import wait\n",
    "preds = preds.persist()\n",
    "_ = wait(preds)\n",
    "\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions to 's3://saturn-titan/nyc-taxi/ml_results/predictions/tip__dask__elastic_net'\n",
      "Done writing predictions\n",
      "CPU times: user 56.9 ms, sys: 0 ns, total: 56.9 ms\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_utils.write_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "If the `preds` DataFrame was _really_ big, you would want to use `dask_ml.metrics.mean_squared_error`. Here, the `preds` columns are pulled down to the client because we're using `sklearn.metrics.mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 620 ms, sys: 978 ms, total: 1.6 s\n",
      "Wall time: 2.62 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_task</th>\n",
       "      <th>tool</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>fit_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tip</td>\n",
       "      <td>dask</td>\n",
       "      <td>elastic_net</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.20726</td>\n",
       "      <td>61.773943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ml_task  tool        model metric    value  fit_seconds\n",
       "0     tip  dask  elastic_net   rmse  0.20726    61.773943"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(preds.actual, preds.predicted, squared=False)\n",
    "ml_utils.write_metric_df('rmse', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
