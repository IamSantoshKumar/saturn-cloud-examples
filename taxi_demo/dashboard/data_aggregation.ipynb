{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import hvplot.dask, hvplot.pandas\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use proper import as in other notebooks\n",
    "\n",
    "ddf = dd.read_parquet(\n",
    "    \"s3://saturn-titan/data/nyc-taxi/taxi_2017_2019/\", \n",
    "    assume_missing=True, \n",
    "    engine=\"pyarrow\"\n",
    ")\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: downsample\n",
    "\n",
    "To run this notebook quickly and get a sense of the results you can downsample and persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf = ddf.sample(frac=0.01).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data\n",
    "\n",
    "We'll distill some features out of the datetime component of the data. This is similar to the feature engineering that is done in other places in this demo, but we'll only create the features that'll be most useful in the visuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[\"pickup_hour\"] = ddf.pickup_datetime.dt.hour\n",
    "ddf[\"dropoff_hour\"] = ddf.dropoff_datetime.dt.hour\n",
    "ddf[\"pickup_weekday\"] = ddf.pickup_datetime.dt.weekday\n",
    "ddf[\"dropoff_weekday\"] = ddf.dropoff_datetime.dt.weekday\n",
    "ddf[\"percent_tip\"] = (ddf[\"tip_amount\"] / ddf[\"fare_amount\"]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries datasets\n",
    "\n",
    "We'll resample to an hourly timestep so that we don't have to pass around so much data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = ddf[[\"pickup_datetime\", \"percent_tip\"]]\n",
    "tips = tips.set_index(\"pickup_datetime\").resample('1H').mean().compute()\n",
    "\n",
    "# make sure to only include real values\n",
    "start = ddf.head(1).pickup_datetime.values[0]\n",
    "end = ddf.tail(1).pickup_datetime.values[0]\n",
    "trimmed = tips[start:end]\n",
    "\n",
    "trimmed.to_csv(\"./data/pickup_average_percent_tip_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = ddf[[\"pickup_datetime\", \"fare_amount\"]]\n",
    "fare = fare.set_index(\"pickup_datetime\").resample('1H').mean().compute()\n",
    "\n",
    "# make sure to only include real values\n",
    "start = ddf.head(1).pickup_datetime.values[0]\n",
    "end = ddf.tail(1).pickup_datetime.values[0]\n",
    "trimmed = fare[start:end]\n",
    "\n",
    "trimmed.to_csv(\"./data/pickup_average_fare_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate datasets\n",
    "\n",
    "Since our data is rather large and will mostly be viewed in grouped aggregates, we can do some aggregation now and save it off for use in plots later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in [\"pickup\", \"dropoff\"]:\n",
    "    data = (ddf\n",
    "            .groupby([\n",
    "                f\"{value}_taxizone_id\", \n",
    "                f\"{value}_hour\",  \n",
    "                f\"{value}_weekday\",\n",
    "            ])\n",
    "            .agg({\n",
    "                \"fare_amount\": [\"mean\", \"count\", \"sum\"],\n",
    "                \"trip_distance\": [\"mean\", \"sum\"],\n",
    "                \"percent_tip\": [\"mean\", \"count\", \"sum\"],\n",
    "            })\n",
    "            .compute()\n",
    "           )\n",
    "    data.columns = data.columns.to_flat_index()\n",
    "    data = data.rename({\n",
    "        (\"fare_amount\", \"mean\"): \"average_fare\",\n",
    "        (\"fare_amount\", \"count\"): \"total_rides\",\n",
    "        (\"fare_amount\", \"sum\"): \"total_fare\",\n",
    "        (\"trip_distance\", \"sum\"): \"total_trip_distance\",\n",
    "        (\"trip_distance\", \"mean\"): \"average_trip_distance\",\n",
    "        (\"percent_tip\", \"mean\"): \"average_percent_tip\",\n",
    "        (\"percent_tip\", \"count\"): \"total_tips\",\n",
    "        (\"percent_tip\", \"sum\"): \"total_percent_tip\",\n",
    "        \n",
    "    }, axis=1).reset_index(level=[1, 2])\n",
    "    data.to_csv(f\"data/{value}_grouped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "To make use of the new datasets we can visualize all the data at once using a grouped heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hvplot.heatmap(\n",
    "    x=\"dropoff_weekday\", \n",
    "    y=\"dropoff_hour\", \n",
    "    C=\"total_rides\",\n",
    "    groupby=\"dropoff_taxizone_id\", \n",
    "    responsive=True, min_height=600, cmap=\"viridis\",\n",
    "    colorbar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can aggregate the data along various axes to derive new meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = data.groupby(\"dropoff_taxizone_id\")[[\"total_fare\", \"total_rides\"]].sum()\n",
    "aggregated[\"average_fare\"] = (aggregated.total_fare / aggregated.total_rides) * 100\n",
    "\n",
    "aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This aggregated dataset can be paired with other information such as geography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "zones = gpd.read_file('./data/taxi_zones.shp').to_crs('epsg:4326')\n",
    "joined = zones.join(aggregated, on=\"LocationID\")\n",
    "\n",
    "joined.hvplot(x=\"longitude\", y=\"latitude\", c=\"average_fare\", logz=True,\n",
    "              geo=True, alpha=0.5, cmap=\"reds\", hover_cols=[\"zone\", \"borough\"], \n",
    "              title=f\"Ride volume by dropoff location\", height=600, width=800, clim=(0, 100), cmap=\"viridis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment Type Pie Chart\n",
    "\n",
    "Other vizualisations can be contructed straight from the raw data and saved for embedding in the dashboard later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_type = ddf.payment_type.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = payment_type.index.map({\n",
    "    \"1\": \"Credit card\", \n",
    "    \"2\": \"Cash\", \n",
    "    \"3\": \"No charge\", \n",
    "    \"4\": \"Dispute\", \n",
    "    \"5\": \"Unknown\", \n",
    "    \"6\": \"Voided trip\"\n",
    "}).astype(\"category\")\n",
    "\n",
    "payment_type.index = new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_type.name = \"value\"\n",
    "payment_type.index.name = \"payment_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "data = payment_type.reset_index()\n",
    "data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "data[\"label\"] = data.value.apply(lambda x: f\"{x/1e6: .0f} M\")\n",
    "data[\"frac\"] = data.angle.apply(lambda x: f\"{x / (2*pi): .0%}\")\n",
    "\n",
    "data = data[:2]\n",
    "data['color'] = [\"thistle\", \"lightblue\"]\n",
    "\n",
    "\n",
    "p = figure(plot_height=350, plot_width=350, toolbar_location=None,\n",
    "           x_range=(-.5, .5), y_range=(0, 2), title=\"Payment Type\")\n",
    "\n",
    "p.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', source=data)\n",
    "\n",
    "p.text(x=[-0.2, 0.07], y=[1.4, 0.7], text=data[\"payment_type\"].astype(str) + \":\\n  \" + data[\"label\"] + \"\\n  \" + data[\"frac\"],\n",
    "       text_align=\"left\", text_baseline=\"top\", text_font_size=\"15px\")\n",
    "\n",
    "\n",
    "p.title.text_font_size = \"20px\"\n",
    "p.axis.axis_label=None\n",
    "p.axis.visible=False\n",
    "p.grid.grid_line_color = None\n",
    "p.outline_line_width = 0\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import export_svgs\n",
    "\n",
    "p.output_backend = \"svg\"\n",
    "export_svgs(p, filename=\"pie_chart.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
